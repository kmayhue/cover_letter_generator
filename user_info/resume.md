# Kenny Mayhue
**Senior Data Engineer**

## PROFESSIONAL EXPERIENCE

### EarthOptics (Full-Time)
**Senior Data Engineer** (Mar 2024 – Jan 2025) | **Data Engineer** (Oct 2022 – Mar 2024)
- Led the development, management, and optimization of the company's BigQuery data warehouse, establishing it as the central source of truth for analytics and business intelligence.
- Built and maintained critical business intelligence dashboards and reports using dbt for data transformation/modeling and Looker Studio for visualization, enabling data-driven decision-making across teams.
- Designed and implemented robust, production-grade data pipelines (Python, SQL, GCP) for diverse datasets including sensor data and satellite imagery, ensuring high data quality for analysis and ML.
- Developed and automated Kubernetes job deployments (Bash) for complex data processing workflows, significantly streamlining operations and reducing manual effort.

### Meta (Contract)
**Data Engineer III** (Sep 2021 – Sep 2022)
- Architected and deployed scalable data pipelines using Python, SQL, and internal Meta frameworks to process user ad data, powering critical Unidash dashboards used for analysis and decision-making.
- Ensured data quality and reliability by leading data validation efforts across pipelines and dashboards, implementing checks and collaborating with stakeholders on data integrity.

### Adoya (Contract)
**Data Engineer** (May 2021 – Dec 2021)
- Developed Python scripts leveraging Pandas to automate data synchronization from the Apple Search Ads API, ensuring data consistency and timeliness for the ad reporting platform.
- Designed and implemented optimized NoSQL data models using AWS DynamoDB for efficient storage and retrieval of ad performance data supporting analytics needs.

### Williams-Sonoma
**Data Analyst** (Mar 2019 – Apr 2021)
- Developed and implemented ETL scripts using Python, SQL, and Shell, orchestrated via cron and Databricks, to support marketing operations and reporting requirements.
- Performed ad-hoc analysis using Teradata, Databricks, and Power BI, and supported the migration of legacy processes to a modern Customer Data Platform (CDP).

### Nielsen
**Data Analyst** (Jul 2018 – Mar 2019)
- Built ETL pipelines using Python and Shell scripting to ingest data from web APIs (Appsflyer) into Hadoop HDFS, supporting data analysis for a major retail client (Walmart).
- Delivered data-driven insights via ad-hoc analysis using big data tools including HiveQL and Spark SQL within Jupyter Notebooks, supporting client initiatives.

### The Fontana Group
**Data Analyst** (Jun 2017 – May 2018)
- Developed Python scripts to extract and process geocoding and traffic data from external APIs, automating data enrichment and analysis workflows.
- Designed and built database applications using MS Access, SQL, and VBA to automate data management processes and reporting tasks.

## SKILLS
- **Programming Languages:** Python, SQL, Bash, HTML, CSS
- **Cloud Technologies:** GCP, BigQuery, Docker, Kubernetes, Airflow
- **Data Transformation:** dbt, Pandas, Geopandas, PySpark, Jinja
- **Databases & Data Storage:** PostgreSQL, BigDynamoDB, Google Cloud Storage
- **Visualization & Reporting Tools:** Looker Studio, Power BI, Unidash, Superset

## EDUCATION
**University of Arizona**, Tucson, AZ
- B.S. Mathematics, Minor in Economics, 2017